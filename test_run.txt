[INFO] Scanning for projects...
[INFO] 
[INFO] --------------------< com.hao:quant-data-collector >--------------------
[INFO] Building quant-data-collector 0.0.1-SNAPSHOT
[INFO]   from pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- resources:3.3.1:resources (default-resources) @ quant-data-collector ---
[INFO] Copying 2 resources from src\main\resources to target\classes
[INFO] Copying 18 resources from src\main\resources to target\classes
[INFO] 
[INFO] --- compiler:3.11.0:compile (default-compile) @ quant-data-collector ---
[INFO] Changes detected - recompiling the module! :source
[INFO] Compiling 164 source files with javac [debug release 21] to target\classes
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/dto/param/topic/TopicInfoParam.java:[72,21] @Builder will ignore the initializing expression entirely. If you want the initializing expression to serve as default, add @Builder.Default. If it is not supposed to be settable during building, make the field final.
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/dto/param/topic/TopicInfoParam.java:[91,20] @Builder will ignore the initializing expression entirely. If you want the initializing expression to serve as default, add @Builder.Default. If it is not supposed to be settable during building, make the field final.
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/dto/param/topic/TopicInfoParam.java:[94,20] @Builder will ignore the initializing expression entirely. If you want the initializing expression to serve as default, add @Builder.Default. If it is not supposed to be settable during building, make the field final.
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/web/vo/abnormal/AbnormalIndexVO.java:[7,1] Generating equals/hashCode implementation but without a call to superclass, even though this class does not extend java.lang.Object. If this is intentional, add '@EqualsAndHashCode(callSuper=false)' to your type.
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/web/vo/limitup/TopicStockVO.java:[6,1] Generating equals/hashCode implementation but without a call to superclass, even though this class does not extend java.lang.Object. If this is intentional, add '@EqualsAndHashCode(callSuper=false)' to your type.
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/web/vo/limitup/ResultObjectVO.java:[9,1] Generating equals/hashCode implementation but without a call to superclass, even though this class does not extend java.lang.Object. If this is intentional, add '@EqualsAndHashCode(callSuper=false)' to your type.
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/dto/table/topic/TopicStockDTO.java:[8,1] Generating equals/hashCode implementation but without a call to superclass, even though this class does not extend java.lang.Object. If this is intentional, add '@EqualsAndHashCode(callSuper=false)' to your type.
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/web/vo/limitup/TopicInfoVO.java:[6,1] Generating equals/hashCode implementation but without a call to superclass, even though this class does not extend java.lang.Object. If this is intentional, add '@EqualsAndHashCode(callSuper=false)' to your type.
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/web/vo/abnormal/ActiveSeatsRankVO.java:[8,1] Generating equals/hashCode implementation but without a call to superclass, even though this class does not extend java.lang.Object. If this is intentional, add '@EqualsAndHashCode(callSuper=false)' to your type.
[WARNING] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/integration/redis/RedisConfig.java:[346,86] 最后一个参数使用了不准确的变量类型的 varargs 方法的非 varargs 调用; 
  对于 varargs 调用, 应使用 java.lang.Object
  对于非 varargs 调用, 应使用 java.lang.Object[], 这样也可以抑制此警告
[INFO] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/dto/param/verification/VerificationQueryParam.java: 某些输入文件使用或覆盖了已过时的 API。
[INFO] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/dto/param/verification/VerificationQueryParam.java: 有关详细信息, 请使用 -Xlint:deprecation 重新编译。
[INFO] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/service/impl/TopicServiceImpl.java: 某些输入文件使用了未经检查或不安全的操作。
[INFO] /E:/project/quant-nano-alpha/services/quant-data-collector/src/main/java/com/hao/datacollector/service/impl/TopicServiceImpl.java: 有关详细信息, 请使用 -Xlint:unchecked 重新编译。
[INFO] 
[INFO] --- resources:3.3.1:testResources (default-testResources) @ quant-data-collector ---
[INFO] skip non existing resourceDirectory E:\project\quant-nano-alpha\services\quant-data-collector\src\test\resources
[INFO] 
[INFO] --- compiler:3.11.0:testCompile (default-testCompile) @ quant-data-collector ---
[INFO] Changes detected - recompiling the module! :dependency
[INFO] Compiling 32 source files with javac [debug release 21] to target\test-classes
[INFO] /E:/project/quant-nano-alpha/services/quant-data-collector/src/test/java/com/hao/datacollector/DistributedLockTest.java: 某些输入文件使用或覆盖了已过时的 API。
[INFO] /E:/project/quant-nano-alpha/services/quant-data-collector/src/test/java/com/hao/datacollector/DistributedLockTest.java: 有关详细信息, 请使用 -Xlint:deprecation 重新编译。
[INFO] /E:/project/quant-nano-alpha/services/quant-data-collector/src/test/java/com/hao/datacollector/report/mysql/PerformanceOatTests.java: 某些输入文件使用了未经检查或不安全的操作。
[INFO] /E:/project/quant-nano-alpha/services/quant-data-collector/src/test/java/com/hao/datacollector/report/mysql/PerformanceOatTests.java: 有关详细信息, 请使用 -Xlint:unchecked 重新编译。
[INFO] 
[INFO] --- surefire:3.5.3:test (default-test) @ quant-data-collector ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.hao.datacollector.service.impl.AiApiServiceImplTest
Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
                                                         
                                                                      ____        _
                                                                     |  _ \  __ _| |_ __ _
                                                                     | | | |/ _` | __/ _` |
                                                                     | |_| | (_| | || (_| |
                                                                     |____/ \__,_|\__\__,_|

                                                          :: dataCollectionService start successfully!
                                                                                   :: Spring Boot :: 3.5.3
                                                         
                                                           项目名称   : quant-data-collector
                                                           运行端口   : 8801
                                                           注册中心   : 127.0.0.1:7000
                                                           当前环境   : dev
                                                           调度中心   : http://127.0.0.1:8802/xxl-job-3.1.0
                                                           执行器名称 : data-collector
                                                         

2026-01-10 16:44:51.537 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
2026-01-10 16:44:51.600 [background-preinit] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 32768
	bootstrap.servers = [192.168.254.2:9092, 192.168.254.3:9092, 192.168.254.4:9092]
	buffer.memory = 67108864
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = snappy
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

INFO: Sentinel log output type is: file
INFO: Sentinel log charset is: utf-8
INFO: Sentinel log base directory is: C:\Users\lihao\logs\csp\
INFO: Sentinel log name use pid is: false
INFO: Sentinel log level is: INFO
2026-01-10 16:44:51.712 [background-preinit] INFO  o.a.k.c.telemetry.internals.KafkaMetricsCollector - initializing Kafka metrics collector
2026-01-10 16:44:51.764 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - Starting AiApiServiceImplTest using Java 21.0.6 with PID 2888 (started by lihao in E:\project\quant-nano-alpha\services\quant-data-collector)
2026-01-10 16:44:51.768 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - The following 1 profile is active: "dev"
2026-01-10 16:44:51.884 [background-preinit] INFO  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
2026-01-10 16:44:51.981 [background-preinit] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2026-01-10 16:44:51.982 [background-preinit] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2026-01-10 16:44:51.982 [background-preinit] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1768034691978
2026-01-10 16:44:52.193 [main] INFO  c.a.cloud.nacos.configdata.NacosConfigDataLoader - [Nacos Config] Load config[dataId=common.yml, group=quant-data-collector] success
2026-01-10 16:44:52.713 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: n8vjTMpNSPWbUOrWJNnHJg
2026-01-10 16:44:52.716 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 7286 with epoch 0
2026-01-10 16:44:52.805 [main] INFO  c.a.cloud.nacos.configdata.NacosConfigDataLoader - [Nacos Config] Load config[dataId=application-dev.yml, group=quant-data-collector] success
2026-01-10 16:44:55.116 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2026-01-10 16:44:55.125 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2026-01-10 16:44:55.229 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 54 ms. Found 0 Redis repository interfaces.
2026-01-10 16:44:55.680 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=0c962dda-39f4-300c-8640-c4403a09863f
2026-01-10 16:44:57.769 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
2026-01-10 16:44:58.220 [main] INFO  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection com.mysql.cj.jdbc.ConnectionImpl@486480e2
2026-01-10 16:44:58.222 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
2026-01-10 16:44:58.278 [main] INFO  c.h.datacollector.service.impl.BaseDataServiceImpl - 交易日历查询结果|Trade_date_query_result,recordSize=247
2026-01-10 16:44:58.287 [main] INFO  c.h.datacollector.service.impl.BaseDataServiceImpl - 交易日历查询结果|Trade_date_query_result,recordSize=6
2026-01-10 16:44:58.294 [main] INFO  c.h.datacollector.service.impl.BaseDataServiceImpl - 交易日历查询结果|Trade_date_query_result,recordSize=243
2026-01-10 16:44:58.303 [main] INFO  c.h.datacollector.service.impl.BaseDataServiceImpl - 交易日历查询结果|Trade_date_query_result,recordSize=243
2026-01-10 16:44:58.311 [main] INFO  c.h.datacollector.service.impl.BaseDataServiceImpl - 交易日历查询结果|Trade_date_query_result,recordSize=242
2026-01-10 16:44:58.319 [main] INFO  c.h.datacollector.service.impl.BaseDataServiceImpl - 交易日历查询结果|Trade_date_query_result,recordSize=242
2026-01-10 16:44:58.324 [main] INFO  c.h.datacollector.service.impl.BaseDataServiceImpl - 交易日历查询结果|Trade_date_query_result,recordSize=242
2026-01-10 16:44:58.329 [main] INFO  c.h.datacollector.service.impl.BaseDataServiceImpl - 交易日历查询结果|Trade_date_query_result,recordSize=243
2026-01-10 16:44:58.331 [main] INFO  com.hao.datacollector.cache.DateCache - 交易日历缓存完成|Trade_date_cache_loaded,thisYearSize=247,currentYearSize=6,year2022Size=242,year2023Size=242,year2024Size=242
2026-01-10 16:44:58.368 [main] INFO  c.hao.datacollector.integration.redis.RedisConfig - 开始初始化Redis连接_-_host:_127.0.0.1,_port:_6379,_database:_0,_timeout:_PT2S,_password:_已配置
2026-01-10 16:44:59.106 [main] INFO  c.hao.datacollector.integration.redis.RedisConfig - Redis连接测试成功
2026-01-10 16:44:59.106 [main] INFO  c.hao.datacollector.integration.redis.RedisConfig - Redis初始化成功_-_连接到_127.0.0.1:6379/0
2026-01-10 16:44:59.887 [main] INFO  com.hao.datacollector.cache.LimitCache - 涨停映射缓存完成|Limit_up_mapping_cache_done,redisKey=DATA_LIMIT_UP_TRADING_DATE_MAPPING_STOCK_MAP,mapSize=1413
2026-01-10 16:44:59.975 [main] INFO  com.hao.datacollector.cache.StockCache - 股票代码补充缓存完成|Stock_supplement_code_cache_loaded,supplementSize=311
2026-01-10 16:44:59.977 [main] INFO  com.hao.datacollector.cache.StockCache - 股票代码缓存完成|Stock_code_cache_loaded,totalSize=5860
2026-01-10 16:45:00.348 [main] INFO  com.hao.datacollector.cache.StockCache - 股票基础信息缓存完成|Stock_base_cache_loaded,baseInfoSize=5549,nameMapSize=5549
2026-01-10 16:45:00.350 [main] INFO  com.hao.datacollector.cache.StockCache - 股票ID映射缓存完成|Stock_id_mapping_cache_loaded,mapSize=5860
2026-01-10 16:45:00.416 [main] INFO  com.hao.datacollector.cache.TopicCache - 题材缓存完成|Topic_cache_loaded,topicStockSize=10449
2026-01-10 16:45:00.672 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - 初始化IO密集型线程池，CPU核数：24
2026-01-10 16:45:00.677 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - IO密集型线程池初始化完成|IO_thread_pool_ready,coreSize=96,maxSize=192,queueSize=1000
2026-01-10 16:45:00.743 [main] INFO  com.hao.datacollector.web.config.OpenAIConfig - 日志记录|Log_message,_Initializing_OpenAI_Client_(Proxy:_127.0.0.1:7890)
2026-01-10 16:45:00.974 [main] INFO  com.hao.datacollector.web.config.GeminiConfig - 初始化Gemini RestTemplate|Initializing_Gemini_RestTemplate,proxy=127.0.0.1:7890
2026-01-10 16:45:01.223 [main] INFO  c.h.d.web.config.HostInfoSystemPropertyInitializer - 主机信息系统属性初始化开始|Host_info_sysprop_init_start
2026-01-10 16:45:01.231 [main] INFO  c.h.d.web.config.HostInfoSystemPropertyInitializer - 主机信息系统属性设置完成|Host_info_sysprop_set_done
2026-01-10 16:45:01.232 [main] INFO  c.h.d.web.config.HostInfoSystemPropertyInitializer - 日志记录|Log_message,HOST_NAME|Host_name,name=hli
2026-01-10 16:45:01.232 [main] INFO  c.h.d.web.config.HostInfoSystemPropertyInitializer - 日志记录|Log_message,HOST_IP|Host_ip,ip=192.168.254.1
2026-01-10 16:45:01.233 [main] INFO  c.h.d.web.config.HostInfoSystemPropertyInitializer - 日志记录|Log_message,server.port|Server_port,port=8801
2026-01-10 16:45:01.234 [main] INFO  c.h.d.web.config.HostInfoSystemPropertyInitializer - 日志记录|Log_message,spring.application.name|Service_name,name=quant-data-collector
2026-01-10 16:45:01.234 [main] INFO  c.h.d.web.config.HostInfoSystemPropertyInitializer - 日志记录|Log_message,spring.profiles.active|Active_profile,profile=dev
2026-01-10 16:45:01.234 [main] INFO  c.h.d.web.config.HostInfoSystemPropertyInitializer - 日志记录|Log_message,logging.kafka.topic|Log_topic,topic=log-quant-data-collector
2026-01-10 16:45:01.281 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - 初始化CPU密集型线程池
2026-01-10 16:45:01.282 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - CPU密集型线程池初始化完成|CPU_thread_pool_ready,coreSize=25,maxSize=48,queueSize=100
2026-01-10 16:45:01.380 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - 初始化混合型线程池|Init_mixed_thread_pool
2026-01-10 16:45:01.381 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - 混合型线程池初始化完成|Mixed_thread_pool_ready,coreSize=48,maxSize=96,queueSize=400
2026-01-10 16:45:01.383 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - 初始化虚拟线程执行器（需要Java_21+）
2026-01-10 16:45:01.386 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - 虚拟线程执行器初始化成功|Virtual_thread_executor_ready
2026-01-10 16:45:01.391 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - 初始化量化交易专用线程池|Init_quant_thread_pool
2026-01-10 16:45:01.393 [main] INFO  com.hao.datacollector.web.config.ThreadPoolConfig - 量化交易专用线程池初始化完成|Quant_thread_pool_ready,coreSize=102,maxSize=122,queueSize=200
2026-01-10 16:45:01.395 [main] INFO  com.hao.datacollector.web.config.XxlJobConfig - 日志记录|Log_message,>>>>>>>>>>>_xxl-job_config_init.
2026-01-10 16:45:02.156 [main] INFO  o.s.b.actuate.endpoint.web.EndpointLinksResolver - Exposing 1 endpoint beneath base path '/actuator'
2026-01-10 16:45:02.282 [main] INFO  c.alibaba.cloud.sentinel.SentinelWebMvcConfigurer - [Sentinel Starter] register SentinelWebInterceptor with urlPatterns: [/**].
2026-01-10 16:45:03.846 [main] INFO  org.springframework.cloud.commons.util.InetUtils - Cannot determine local hostname
2026-01-10 16:45:03.872 [main] INFO  c.g.x.k.s.configuration.Knife4jAutoConfiguration - init CorsFilter...
2026-01-10 16:45:05.413 [main] INFO  org.springframework.cloud.commons.util.InetUtils - Cannot determine local hostname
2026-01-10 16:45:05.452 [main] INFO  com.xxl.job.core.executor.XxlJobExecutor - >>>>>>>>>>> xxl-job register jobhandler success, name:abnormalIndexJob, jobHandler:com.xxl.job.core.handler.impl.MethodJobHandler@7a9c91e7[class com.hao.datacollector.service.job.AbnormalJob#todayAbnormalIndexTransferJob]
2026-01-10 16:45:05.455 [main] INFO  com.xxl.job.core.executor.XxlJobExecutor - >>>>>>>>>>> xxl-job register jobhandler success, name:limitUpJob, jobHandler:com.xxl.job.core.handler.impl.MethodJobHandler@2b7e07e0[class com.hao.datacollector.service.job.LimitJob#todayLimitUpTransferJob]
2026-01-10 16:45:05.455 [main] INFO  com.xxl.job.core.executor.XxlJobExecutor - >>>>>>>>>>> xxl-job register jobhandler success, name:newsBaseTransferJob, jobHandler:com.xxl.job.core.handler.impl.MethodJobHandler@37717b97[class com.hao.datacollector.service.job.NewsJob#newsBaseTransferJob]
2026-01-10 16:45:05.548 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - Started AiApiServiceImplTest in 17.337 seconds (process running for 18.635)
2026-01-10 16:45:05.562 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 主机信息初始化开始|Host_info_init_start
2026-01-10 16:45:05.567 [scheduling-3] INFO  c.hao.datacollector.web.config.ThreadPoolMonitor - 线程池监控|Thread_pool_stats,type=IO,active=0,poolSize=0,queueSize=0,completed=0
2026-01-10 16:45:05.567 [scheduling-3] INFO  c.hao.datacollector.web.config.ThreadPoolMonitor - 线程池监控|Thread_pool_stats,type=CPU,active=0,poolSize=0,queueSize=0,completed=0
2026-01-10 16:45:05.574 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 主机信息获取成功|Host_info_loaded
2026-01-10 16:45:05.575 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 主机名|Host_name,name=hli
2026-01-10 16:45:05.575 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 主机IP|Host_ip,ip=192.168.254.1
2026-01-10 16:45:05.575 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 服务端口|Service_port,port=8801
2026-01-10 16:45:05.576 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 实例ID|Instance_id,instanceId=quant-data-collector-192.168.254.1-8801
2026-01-10 16:45:05.576 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 服务名|Service_name,name=quant-data-collector
2026-01-10 16:45:05.576 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 运行环境|Active_profile,profile=dev
2026-01-10 16:45:05.577 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 日志主题|Log_topic,topic=log-quant-data-collector
2026-01-10 16:45:05.577 [main] INFO  com.hao.datacollector.config.HostInfoInitializer - 主机信息初始化完成|Host_info_init_done
2026-01-10 16:45:05.580 [main] INFO  com.alibaba.nacos.client.config.impl.CacheData - config listener notify warn timeout millis use default 60000 millis 
2026-01-10 16:45:05.580 [main] INFO  com.alibaba.nacos.client.config.impl.CacheData - nacos.cache.data.init.snapshot = true 
2026-01-10 16:45:05.582 [main] INFO  com.alibaba.nacos.client.config.impl.ClientWorker - [fixed-dev-127.0.0.1_7000] [subscribe] application-dev.yml+quant-data-collector+dev
2026-01-10 16:45:05.594 [main] INFO  com.alibaba.nacos.client.config.impl.CacheData - [fixed-dev-127.0.0.1_7000] [add-listener] ok, tenant=dev, dataId=application-dev.yml, group=quant-data-collector, cnt=1
2026-01-10 16:45:05.595 [main] INFO  com.hao.datacollector.DataCollectorApplication - 启动配置监听|Start_config_listener
2026-01-10 16:45:05.597 [main] INFO  com.alibaba.nacos.client.config.impl.CacheData - [fixed-dev-127.0.0.1_7000] [add-listener] ok, tenant=dev, dataId=application-dev.yml, group=quant-data-collector, cnt=2
2026-01-10 16:45:05.598 [main] INFO  c.a.cloud.nacos.refresh.NacosContextRefresher - [Nacos Config] Listening config: dataId=application-dev.yml, group=quant-data-collector
2026-01-10 16:45:05.599 [main] INFO  com.alibaba.nacos.client.config.impl.ClientWorker - [fixed-dev-127.0.0.1_7000] [subscribe] common.yml+quant-data-collector+dev
2026-01-10 16:45:05.600 [main] INFO  com.alibaba.nacos.client.config.impl.CacheData - [fixed-dev-127.0.0.1_7000] [add-listener] ok, tenant=dev, dataId=common.yml, group=quant-data-collector, cnt=1
2026-01-10 16:45:05.601 [main] INFO  c.a.cloud.nacos.refresh.NacosContextRefresher - [Nacos Config] Listening config: dataId=common.yml, group=quant-data-collector
2026-01-10 16:45:05.601 [main] INFO  com.hao.datacollector.web.config.GeminiConfig - 开始加载Gemini可用模型列表|Start_loading_Gemini_models
2026-01-10 16:45:05.611 [Thread-20] INFO  com.xxl.job.core.server.EmbedServer - >>>>>>>>>>> xxl-job remoting server start success, nettype = class com.xxl.job.core.server.EmbedServer, port = 8901
2026-01-10 16:45:05.619 [xxl-job, executor ExecutorRegistryThread] ERROR com.xxl.job.core.util.XxlJobRemotingUtil - Connection refused: getsockopt
java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:592)
	at java.base/java.net.Socket.connect(Socket.java:751)
	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:178)
	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:531)
	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:636)
	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:280)
	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:386)
	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:408)
	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1319)
	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1252)
	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1138)
	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1067)
	at com.xxl.job.core.util.XxlJobRemotingUtil.postBody(XxlJobRemotingUtil.java:99)
	at com.xxl.job.core.biz.client.AdminBizClient.registry(AdminBizClient.java:46)
	at com.xxl.job.core.thread.ExecutorRegistryThread$1.run(ExecutorRegistryThread.java:48)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2026-01-10 16:45:05.620 [xxl-job, executor ExecutorRegistryThread] INFO  com.xxl.job.core.thread.ExecutorRegistryThread - >>>>>>>>>>> xxl-job registry fail, registryParam:RegistryParam{registryGroup='EXECUTOR', registryKey='data-collector', registryValue='http://127.0.0.1:8901/'}, registryResult:ReturnT [code=500, msg=xxl-job remoting error(Connection refused: getsockopt), for url : http://127.0.0.1:8802/xxl-job-3.1.0/api/registry, content=null]
2026-01-10 16:45:06.987 [main] INFO  com.hao.datacollector.web.config.GeminiConfig - Gemini模型列表加载完成|Gemini_models_loaded,count=100
2026-01-10 16:45:06.987 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 应用启动完成开始更新Kafka配置|App_ready_update_kafka_logback
2026-01-10 16:45:06.993 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 找到KafkaAppender开始更新配置|Kafka_appender_found_update_start
2026-01-10 16:45:06.993 [main] INFO  org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2026-01-10 16:45:07.000 [main] INFO  org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
mvn : 16:45:07,000 |-WARN in com.github.danielwegener.logba
ck.kafka.KafkaAppender[kafkaAppender] - Attempted to append
 to non started appender [kafkaAppender].
所在位置 行:1 字符: 1
+ mvn test -pl services/quant-data-collector -Dtest="AiApiS
erviceImplTe ...
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~
    + CategoryInfo          : NotSpecified: (16:45:07,000  
   |-...kafkaAppender].:String) [], RemoteException
    + FullyQualifiedErrorId : NativeCommandError
 
16:45:07,000 |-WARN in com.github.danielwegener.logback.kaf
ka.KafkaAppender[kafkaAppender] - Attempted to append to no
n started appender [kafkaAppender].
2026-01-10 16:45:07.000 [main] INFO  org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
16:45:07,000 |-WARN in com.github.danielwegener.logback.kaf
ka.KafkaAppender[kafkaAppender] - Attempted to append to no
n started appender [kafkaAppender].
2026-01-10 16:45:07.000 [main] INFO  org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2026-01-10 16:45:07.001 [main] INFO  org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
2026-01-10 16:45:07.001 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
2026-01-10 16:45:07.003 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - Kafka配置更新成功|Kafka_logback_update_done
2026-01-10 16:45:07.003 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - Kafka集群|Kafka_bootstrap,bootstrap=192.168.254.2:9092,192.168.254.3:9092,192.168.254.4:9092
2026-01-10 16:45:07.003 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 主机名|Host_name,name=hli
2026-01-10 16:45:07.004 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 主机IP|Host_ip,ip=192.168.254.1
2026-01-10 16:45:07.004 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 服务端口|Service_port,port=8801
2026-01-10 16:45:07.004 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 服务名|Service_name,name=quant-data-collector
2026-01-10 16:45:07.004 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 运行环境|Active_profile,profile=dev
2026-01-10 16:45:07.004 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 日志主题|Log_topic,topic=log-quant-data-collector
2026-01-10 16:45:07.005 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 实例ID|Instance_id,instanceId=quant-data-collector-192.168.254.1-8801
2026-01-10 16:45:07.005 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - Kafka日志推送恢复|Kafka_log_push_recovered
2026-01-10 16:45:07.006 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 应用启动完成开始更新Kafka配置|App_ready_update_kafka_logback
2026-01-10 16:45:07.012 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 找到KafkaAppender开始更新配置|Kafka_appender_found_update_start
2026-01-10 16:45:07.013 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - Kafka配置更新成功|Kafka_logback_update_done
2026-01-10 16:45:07.015 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - Kafka集群|Kafka_bootstrap,bootstrap=192.168.254.2:9092,192.168.254.3:9092,192.168.254.4:9092
2026-01-10 16:45:07.015 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 主机名|Host_name,name=hli
2026-01-10 16:45:07.015 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 主机IP|Host_ip,ip=192.168.254.1
2026-01-10 16:45:07.015 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 服务端口|Service_port,port=8801
2026-01-10 16:45:07.015 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 服务名|Service_name,name=quant-data-collector
2026-01-10 16:45:07.015 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 运行环境|Active_profile,profile=dev
2026-01-10 16:45:07.016 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 日志主题|Log_topic,topic=log-quant-data-collector
2026-01-10 16:45:07.016 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - 实例ID|Instance_id,instanceId=quant-data-collector-192.168.254.1-8801
2026-01-10 16:45:07.016 [main] INFO  c.hao.datacollector.web.config.KafkaLogbackConfig - Kafka日志推送恢复|Kafka_log_push_recovered
Mockito is currently self-attaching to enable the inline-mo
ck-maker. This will no longer work in future releases of th
e JDK. Please add Mockito as an agent to your build as desc
ribed in Mockito's documentation: https://javadoc.io/doc/or
g.mockito/mockito-core/latest/org.mockito/org/mockito/Mocki
to.html#0.3
Java HotSpot(TM) 64-Bit Server VM warning: Sharing is only 
supported for boot loader classes because bootstrap classpa
th has been appended
WARNING: A Java agent has been loaded dynamically (D:\maven
3.9.9\repository\net\bytebuddy\byte-buddy-agent\1.17.6\byte
-buddy-agent-1.17.6.jar)
WARNING: If a serviceability tool is in use, please run wit
h -XX:+EnableDynamicAgentLoading to hide this warning
WARNING: If a serviceability tool is not in use, please run
 with -Djdk.instrument.traceUsage for more information
WARNING: Dynamic loading of agents will be disallowed by de
fault in a future release
2026-01-10 16:45:07.597 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 当前测试加载的 API Key: AIzaS***
2026-01-10 16:45:07.598 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 环境检查通过：API Key 已配置，网络连通性正常
2026-01-10 16:45:07.602 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 开始测试Gemini最大Token支持|Start_testing_Gemini_max_token_limit
2026-01-10 16:45:07.602 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - ================================================
2026-01-10 16:45:07.602 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - Token 限制测试开始 | Token Limit Test Start
2026-01-10 16:45:07.602 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - ================================================
2026-01-10 16:45:07.602 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 测试目标: 100 tokens (实际约 232 字符, 估算 116 tokens)
2026-01-10 16:45:07.602 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - 调用Gemini对话接口|Calling_Gemini_chat_interface,model=gemma-3-1b-it,input=请阅读以下文本并给出一句话总结：

这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本

请用一句话总结上述内容。
2026-01-10 16:45:09.276 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - Gemini调用成功|Gemini_chat_success,output=这段文本旨在测试API的Token限制，通过逐步增加文本长度来评估其最大输入量。

2026-01-10 16:45:09.277 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest -   -> 成功 | 1675ms | 回复长度: 41
2026-01-10 16:45:11.287 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 测试目标: 500 tokens (实际约 1032 字符, 估算 516 tokens)
2026-01-10 16:45:11.287 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - 调用Gemini对话接口|Calling_Gemini_chat_interface,model=gemma-3-1b-it,input=请阅读以下文本并给出一句话总结：

这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试To

请用一句话总结上述内容。
2026-01-10 16:45:12.233 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - Gemini调用成功|Gemini_chat_success,output=这段文本是测试API最大输入限制的中文文本，旨在通过逐步增加文本长度来确定API的限制范围。

2026-01-10 16:45:12.233 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest -   -> 成功 | 946ms | 回复长度: 47
2026-01-10 16:45:14.233 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 测试目标: 1000 tokens (实际约 2032 字符, 估算 1016 tokens)
2026-01-10 16:45:14.233 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - 调用Gemini对话接口|Calling_Gemini_chat_interface,model=gemma-3-1b-it,input=请阅读以下文本并给出一句话总结：

这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本

请用一句话总结上述内容。
2026-01-10 16:45:15.397 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - Gemini调用成功|Gemini_chat_success,output=这段文本展示了对APIToken限制的测试需求，强调了量化交易系统需要分析大量市场数据和新闻资讯，并持续增加文本长度以探测其最大输入限制。
2026-01-10 16:45:15.397 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest -   -> 成功 | 1164ms | 回复长度: 69
2026-01-10 16:45:17.398 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 测试目标: 2000 tokens (实际约 4032 字符, 估算 2016 tokens)
2026-01-10 16:45:17.398 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - 调用Gemini对话接口|Calling_Gemini_chat_interface,model=gemma-3-1b-it,input=请阅读以下文本并给出一句话总结：

这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的

请用一句话总结上述内容。
2026-01-10 16:45:18.401 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - Gemini调用成功|Gemini_chat_success,output=这段文本旨在测试API的Token限制，通过逐步增加文本长度来评估其最大输入量。
2026-01-10 16:45:18.401 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest -   -> 成功 | 1003ms | 回复长度: 40
2026-01-10 16:45:20.416 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 测试目标: 5000 tokens (实际约 10032 字符, 估算 5016 tokens)
2026-01-10 16:45:20.416 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - 调用Gemini对话接口|Calling_Gemini_chat_interface,model=gemma-3-1b-it,input=请阅读以下文本并给出一句话总结：

这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试To

请用一句话总结上述内容。
2026-01-10 16:45:21.901 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - Gemini调用成功|Gemini_chat_success,output=这段文本描述了测试API最大输入限制的流程，需要逐步增加文本长度以探测其限制。
2026-01-10 16:45:21.901 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest -   -> 成功 | 1485ms | 回复长度: 39
2026-01-10 16:45:23.916 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 测试目标: 10000 tokens (实际约 20032 字符, 估算 10016 tokens)
2026-01-10 16:45:23.916 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - 调用Gemini对话接口|Calling_Gemini_chat_interface,model=gemma-3-1b-it,input=请阅读以下文本并给出一句话总结：

这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本

请用一句话总结上述内容。
2026-01-10 16:45:24.382 [main] ERROR c.hao.datacollector.service.impl.AiApiServiceImpl - Gemini请求失败|Gemini_request_failed
org.springframework.web.client.HttpClientErrorException$TooManyRequests: 429 Too Many Requests on POST request for "https://generativelanguage.googleapis.com/v1beta/models/gemma-3-1b-it:generateContent": "{<EOL>  "error": {<EOL>    "code": 429,<EOL>    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 15000, model: gemma-3-1b\nPlease retry in 33.00012324s.",<EOL>    "status": "RESOURCE_EXHAUSTED",<EOL>    "details": [<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.Help",<EOL>        "links": [<EOL>          {<EOL>            "description": "Learn more about Gemini API quotas",<EOL>            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"<EOL>          }<EOL>        ]<EOL>      },<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.QuotaFailure",<EOL>        "violations": [<EOL>          {<EOL>            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count",<EOL>            "quotaId": "GenerateContentInputTokensPerModelPerMinute-FreeTier",<EOL>            "quotaDimensions": {<EOL>              "model": "gemma-3-1b",<EOL>              "location": "global"<EOL>            },<EOL>            "quotaValue": "15000"<EOL>          }<EOL>        ]<EOL>      },<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.RetryInfo",<EOL>        "retryDelay": "33s"<EOL>      }<EOL>    ]<EOL>  }<EOL>}<EOL>"
	at org.springframework.web.client.HttpClientErrorException.create(HttpClientErrorException.java:130)
	at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:186)
	at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:147)
	at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:953)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:902)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:801)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:683)
	at com.hao.datacollector.service.impl.AiApiServiceImpl.geminiChat(AiApiServiceImpl.java:151)
	at com.hao.datacollector.service.impl.AiApiServiceImplTest.testGeminiMaxTokenLimit(AiApiServiceImplTest.java:722)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:775)
	at org.junit.platform.commons.support.ReflectionSupport.invokeMethod(ReflectionSupport.java:479)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:161)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:152)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:91)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:112)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:94)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:87)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:216)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:212)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:137)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:69)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:156)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39)
	at org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25)
	at org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.apache.maven.surefire.junitplatform.LazyLauncher.execute(LazyLauncher.java:56)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:194)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
2026-01-10 16:45:24.383 [main] WARN  c.h.d.service.impl.AiApiServiceImplTest -   -> 失败 | 467ms | 错误: Error while contacting Gemini: 429 Too Many Requests on POST request for "https://generativelanguage
2026-01-10 16:45:26.388 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 测试目标: 20000 tokens (实际约 40032 字符, 估算 20016 tokens)
2026-01-10 16:45:26.388 [main] INFO  c.hao.datacollector.service.impl.AiApiServiceImpl - 调用Gemini对话接口|Calling_Gemini_chat_interface,model=gemma-3-1b-it,input=请阅读以下文本并给出一句话总结：

这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的最大输入限制。量化交易系统需要分析大量的市场数据和新闻资讯，因此了解API的token限制非常重要。这是一段用于测试Token限制的中文文本。我们需要逐步增加文本长度来探测API的

请用一句话总结上述内容。
2026-01-10 16:45:27.017 [main] ERROR c.hao.datacollector.service.impl.AiApiServiceImpl - Gemini请求失败|Gemini_request_failed
org.springframework.web.client.HttpClientErrorException$TooManyRequests: 429 Too Many Requests on POST request for "https://generativelanguage.googleapis.com/v1beta/models/gemma-3-1b-it:generateContent": "{<EOL>  "error": {<EOL>    "code": 429,<EOL>    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 15000, model: gemma-3-1b\nPlease retry in 30.33972531s.",<EOL>    "status": "RESOURCE_EXHAUSTED",<EOL>    "details": [<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.Help",<EOL>        "links": [<EOL>          {<EOL>            "description": "Learn more about Gemini API quotas",<EOL>            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"<EOL>          }<EOL>        ]<EOL>      },<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.QuotaFailure",<EOL>        "violations": [<EOL>          {<EOL>            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count",<EOL>            "quotaId": "GenerateContentInputTokensPerModelPerMinute-FreeTier",<EOL>            "quotaDimensions": {<EOL>              "location": "global",<EOL>              "model": "gemma-3-1b"<EOL>            },<EOL>            "quotaValue": "15000"<EOL>          }<EOL>        ]<EOL>      },<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.RetryInfo",<EOL>        "retryDelay": "30s"<EOL>      }<EOL>    ]<EOL>  }<EOL>}<EOL>"
	at org.springframework.web.client.HttpClientErrorException.create(HttpClientErrorException.java:130)
	at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:186)
	at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:147)
	at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:953)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:902)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:801)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:683)
	at com.hao.datacollector.service.impl.AiApiServiceImpl.geminiChat(AiApiServiceImpl.java:151)
	at com.hao.datacollector.service.impl.AiApiServiceImplTest.testGeminiMaxTokenLimit(AiApiServiceImplTest.java:722)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:775)
	at org.junit.platform.commons.support.ReflectionSupport.invokeMethod(ReflectionSupport.java:479)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:161)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:152)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:91)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:112)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:94)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:87)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:216)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:212)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:137)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:69)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:156)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39)
	at org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25)
	at org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.apache.maven.surefire.junitplatform.LazyLauncher.execute(LazyLauncher.java:56)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:194)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
2026-01-10 16:45:27.018 [main] WARN  c.h.d.service.impl.AiApiServiceImplTest -   -> 失败 | 630ms | 错误: Error while contacting Gemini: 429 Too Many Requests on POST request for "https://generativelanguage
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 连续失败，停止测试
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - ================================================
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - Token 限制测试报告 | Token Limit Test Report
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - ================================================
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 测试轮数: 7
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 最大成功 Token 数(估算): 5016
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 首次失败 Token 数(估算): 10016
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - 推测 Token 上限区间: 5016 ~ 10016
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - ------------------------------------------------
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - [SUCCESS] 100 tokens, 232 chars, 1675ms, 这段文本旨在测试API的Token限制，通过逐步增加文本长度来评估其最大输入量。 
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - [SUCCESS] 500 tokens, 1032 chars, 946ms, 这段文本是测试API最大输入限制的中文文本，旨在通过逐步增加文本长度来确定API的限制范围。 
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - [SUCCESS] 1000 tokens, 2032 chars, 1164ms, 这段文本展示了对APIToken限制的测试需求，强调了量化交易系统需要分析大量市场数据和新闻资讯，并持续增加文本长度以探测其最大输入限制。
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - [SUCCESS] 2000 tokens, 4032 chars, 1003ms, 这段文本旨在测试API的Token限制，通过逐步增加文本长度来评估其最大输入量。
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - [SUCCESS] 5000 tokens, 10032 chars, 1485ms, 这段文本描述了测试API最大输入限制的流程，需要逐步增加文本长度以探测其限制。
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - [FAILED] 10000 tokens, 20032 chars, 467ms, Error while contacting Gemini: 429 Too Many Requests on POST request for "https://generativelanguage.googleapis.com/v1beta/models/gemma-3-1b-it:generateContent": "{<EOL>  "error": {<EOL>    "code": 429,<EOL>    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 15000, model: gemma-3-1b\nPlease retry in 33.00012324s.",<EOL>    "status": "RESOURCE_EXHAUSTED",<EOL>    "details": [<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.Help",<EOL>        "links": [<EOL>          {<EOL>            "description": "Learn more about Gemini API quotas",<EOL>            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"<EOL>          }<EOL>        ]<EOL>      },<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.QuotaFailure",<EOL>        "violations": [<EOL>          {<EOL>            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count",<EOL>            "quotaId": "GenerateContentInputTokensPerModelPerMinute-FreeTier",<EOL>            "quotaDimensions": {<EOL>              "model": "gemma-3-1b",<EOL>              "location": "global"<EOL>            },<EOL>            "quotaValue": "15000"<EOL>          }<EOL>        ]<EOL>      },<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.RetryInfo",<EOL>        "retryDelay": "33s"<EOL>      }<EOL>    ]<EOL>  }<EOL>}<EOL>"
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - [FAILED] 20000 tokens, 40032 chars, 630ms, Error while contacting Gemini: 429 Too Many Requests on POST request for "https://generativelanguage.googleapis.com/v1beta/models/gemma-3-1b-it:generateContent": "{<EOL>  "error": {<EOL>    "code": 429,<EOL>    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 15000, model: gemma-3-1b\nPlease retry in 30.33972531s.",<EOL>    "status": "RESOURCE_EXHAUSTED",<EOL>    "details": [<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.Help",<EOL>        "links": [<EOL>          {<EOL>            "description": "Learn more about Gemini API quotas",<EOL>            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"<EOL>          }<EOL>        ]<EOL>      },<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.QuotaFailure",<EOL>        "violations": [<EOL>          {<EOL>            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count",<EOL>            "quotaId": "GenerateContentInputTokensPerModelPerMinute-FreeTier",<EOL>            "quotaDimensions": {<EOL>              "location": "global",<EOL>              "model": "gemma-3-1b"<EOL>            },<EOL>            "quotaValue": "15000"<EOL>          }<EOL>        ]<EOL>      },<EOL>      {<EOL>        "@type": "type.googleapis.com/google.rpc.RetryInfo",<EOL>        "retryDelay": "30s"<EOL>      }<EOL>    ]<EOL>  }<EOL>}<EOL>"
2026-01-10 16:45:27.018 [main] INFO  c.h.d.service.impl.AiApiServiceImplTest - ================================================
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.40 s -- in com.hao.datacollector.service.impl.AiApiServiceImplTest
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  01:02 min
[INFO] Finished at: 2026-01-10T16:45:37+08:00
[INFO] ------------------------------------------------------------------------
